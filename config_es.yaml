hidden_layer_size: 64
activation: "relu"
batch_norm: "false"
init_mode: "normal"
n_hidden_layers: 1
pop_size: 200
sigma: 0.01
learning_rate: 0.01
epochs: 100
batch_size: 256
early_stopping_epochs: 1000
alpha_reg_pca: 0.0
pca_type: "regular"
partial_contribution_objective: "true"
num_components: 1
dataset: "circles"
number_of_runs: 1
remove_outliers: false
n_outliers: 15
plot: false
val_prop: 0.25



