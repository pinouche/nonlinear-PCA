hidden_layer_size: 64
activation: "relu"
batch_norm: true
init_mode: "normal"
n_hidden_layers: 1
pop_size: 200
sigma: 0.01
learning_rate: 0.01
epochs: 2500
batch_size: 128
early_stopping_epochs: 30000
alpha_reg_pca: 0.0
pca_type: "regular"
partial_contribution_objective: false
num_components: 1
dataset: "circles"
number_of_runs: 15
remove_outliers: false
n_outliers: 15
plot: false
val_prop: 0.25



